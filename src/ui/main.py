import streamlit as st
import pandas as pd
import os
import sys
import zipfile
import shutil
import time
from collections import defaultdict
from streamlit_option_menu import option_menu

# Agregar el directorio ra铆z del proyecto a sys.path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../..")))
from src.extraction.pdf_reader import extract_data_from_pdf
from src.processing.report_generator import generate_excel_report

# Configuraci贸n de la p谩gina (quitamos 'wide')
st.set_page_config(page_title="Procesador de Entrevistas")

# Estilos CSS personalizados
st.markdown(
    """
    <style>
        .header {
            text-align: center;
            font-size: 36px;
            font-weight: bold;
            color: #00A86B;
            padding: 10px;
        }
        .subheader {
            text-align: center;
            font-size: 20px;
            color: #EEEEEE;
            margin-bottom: 20px;
        }
    </style>
    <div class="header"> Procesador de Entrevistas</div>
    <div class="subheader">Automatizaci贸n del procesamiento de entrevistas y generaci贸n de reportes</div>
    """,
    unsafe_allow_html=True
)

# Men煤 de selecci贸n de secci贸n
seccion = option_menu(
    menu_title=" Selecciona la carrera",
    options=["Medicina / Ingenier铆a Biom茅dica", "Todas las carreras, excepto Medicina"],
    icons=["activity", "book"],
    default_index=0,
    orientation="vertical"
)

multiple_pdfs = seccion == "Medicina / Ingenier铆a Biom茅dica"

# Carpeta de trabajo
DATA_FOLDER = "data"
os.makedirs(DATA_FOLDER, exist_ok=True)

def clear_data_folder():
    for file in os.listdir(DATA_FOLDER):
        file_path = os.path.join(DATA_FOLDER, file)
        try:
            os.chmod(file_path, 0o777)
            os.remove(file_path)
        except Exception as e:
            print(f"Error al eliminar {file_path}: {e}")

# Subida de archivos ZIP o PDFs
st.subheader(" Sube archivos PDF en ambas secciones. ZIPs permitidos solo en 'Todas las carreras'.")
uploaded_files = st.file_uploader("Selecciona archivos PDF o un ZIP", type=["pdf", "zip"], accept_multiple_files=True, key="file_uploader")

pdf_files = []
zip_files = []

if uploaded_files:
    clear_data_folder()
    
    for file in uploaded_files:
        if file.name.endswith(".zip"):
            zip_path = os.path.join(DATA_FOLDER, file.name)
            with open(zip_path, "wb") as f:
                f.write(file.getbuffer())
            zip_files.append(zip_path)
        else:
            temp_path = os.path.join(DATA_FOLDER, file.name)
            with open(temp_path, "wb") as f:
                f.write(file.getbuffer())
            pdf_files.append(temp_path)
    
    # Procesar ZIPs
    for zip_path in zip_files:
        with zipfile.ZipFile(zip_path, 'r') as zip_ref:
            zip_ref.extractall(DATA_FOLDER)
        os.remove(zip_path)
    
    pdf_files = [os.path.join(DATA_FOLDER, f) for f in os.listdir(DATA_FOLDER) if f.endswith(".pdf")]

st.subheader(f" Archivos Procesados: {len(pdf_files)}")

if pdf_files:
    extracted_data = defaultdict(list)
    uploaded_files_info = {}
    duplicated_files = []
    
    for pdf_path in pdf_files:
        data = extract_data_from_pdf(pdf_path)
        if data:
            dni = data["documento"].strip()
            entrevistador = data.get("entrevistador", "Desconocido")
            
            if dni in extracted_data:
                entrevistadores_existentes = [r["entrevistador"] for r in extracted_data[dni]]
                if multiple_pdfs and entrevistador not in entrevistadores_existentes:
                    extracted_data[dni].append(data)
                else:
                    duplicated_files.append(f"DNI {dni} - Entrevistador: {entrevistador}")
                    continue
            else:
                extracted_data[dni].append(data)
    
    valid_data = []
    errores = []
    
    for dni, registros in extracted_data.items():
        if (multiple_pdfs and len(registros) == 2) or (not multiple_pdfs and len(registros) == 1):
            # Ordenar los registros por el nombre del entrevistador para mantener consistencia
            registros = sorted(registros, key=lambda x: x["entrevistador"])
            
            merged_data = {
                "codigo": registros[0]["codigo"],
                "modalidad": registros[0]["modalidad"],
                "programa": registros[0]["programa"],
                "documento": dni,
                "Nota Entrevistador 1": int(registros[0]["total"]),
                "Nombre Entrevistador 1": registros[0]["entrevistador"]
            }
            if multiple_pdfs:
                merged_data["Nota Entrevistador 2"] = int(registros[1]["total"])
                merged_data["Nombre Entrevistador 2"] = registros[1]["entrevistador"]
                merged_data["Total"] = merged_data["Nota Entrevistador 1"] + merged_data["Nota Entrevistador 2"]
            valid_data.append(merged_data)
        else:
            entrevistadores = ", ".join([r["entrevistador"] for r in registros])
            errores.append(f"El DNI {dni} (Entrevistador: {entrevistadores}) tiene {len(registros)} archivo(s) en lugar de {'2' if multiple_pdfs else '1'}.")
    
    df = pd.DataFrame(valid_data)
    st.subheader(" Datos Extra铆dos")
    st.dataframe(df)
    
    if errores or duplicated_files:
        st.subheader("锔 Archivos con Errores")
        for error in errores:
            st.error(error)
        for duplicate in duplicated_files:
            st.warning(f" Archivo duplicado detectado: {duplicate}")
    
    if not df.empty and st.button(" Generar Reporte en Excel"):
        excel_path = generate_excel_report(df)
        with open(excel_path, "rb") as f:
            st.download_button(label=" Descargar Reporte Excel", data=f, file_name="Reporte_Entrevistas.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
